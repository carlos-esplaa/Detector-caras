{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa435b1b",
   "metadata": {},
   "source": [
    "# Detección de caras:\n",
    "- Raquel Almeida Quesada.\n",
    "- Carlos Santana Esplá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3591b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee0097",
   "metadata": {},
   "source": [
    "### Cargar conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bb48edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def target_transform_fixed(label):\n",
    "    # Esta función simplemente devuelve la etiqueta sin cambios\n",
    "    return label\n",
    "\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def make_dataset(root, transform=None, target_transform=None):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(root):\n",
    "        path = os.path.join(root, filename)\n",
    "        images.append(path)\n",
    "        \n",
    "        # Etiquetas basadas en el nombre del archivo\n",
    "        if 'easy' in filename:\n",
    "            labels.append(0)  # Falso\n",
    "        elif 'real' in filename:\n",
    "            labels.append(1)  # Real\n",
    "        else:\n",
    "            labels.append(-1)  # Etiqueta desconocida o sin etiqueta\n",
    "\n",
    "    return list(zip(images, labels))\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_list, transform=None, target_transform=None):\n",
    "        self.dataset_list = dataset_list\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.dataset_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        img = transforms.ToTensor()(img)  # Convertir la imagen a tensor\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset_fake = CustomDataset(\n",
    "    make_dataset(r'./Datos/real_and_fake_face/training_fake'),\n",
    "    target_transform=target_transform_fixed,\n",
    ")\n",
    "\n",
    "train_dataset_real = CustomDataset(\n",
    "    make_dataset(r'./Datos/real_and_fake_face/training_real'),\n",
    "    target_transform=target_transform_fixed,\n",
    ")\n",
    "\n",
    "train_loader_fake = DataLoader(train_dataset_fake, batch_size=32, shuffle=True, num_workers=0)\n",
    "train_loader_real = DataLoader(train_dataset_real, batch_size=32, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d97d675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = models.resnet18(pretrained=True)\n",
    "        self.features.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04743fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs_fake, _ in train_loader_fake:\n",
    "        labels_fake = torch.zeros(inputs_fake.size(0), 1).to(device)\n",
    "        outputs_fake = model(inputs_fake.to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_fake = criterion(outputs_fake, labels_fake)\n",
    "        loss_fake.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    for inputs_real, _ in train_loader_real:\n",
    "        labels_real = torch.ones(inputs_real.size(0), 1).to(device)\n",
    "        outputs_real = model(inputs_real.to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_real = criterion(outputs_real, labels_real)\n",
    "        loss_real.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluar el modelo en el conjunto de prueba para calcular el accuracy\n",
    "    model.eval()\n",
    "    correct_fake = 0\n",
    "    total_fake = 0\n",
    "    for inputs_fake, _ in test_loader_fake:\n",
    "        labels_fake = torch.zeros(inputs_fake.size(0), 1).to(device)\n",
    "        outputs_fake = model(inputs_fake.to(device))\n",
    "        predictions_fake = (outputs_fake > 0.5).float()\n",
    "        correct_fake += (predictions_fake == labels_fake).sum().item()\n",
    "        total_fake += labels_fake.size(0)\n",
    "\n",
    "    correct_real = 0\n",
    "    total_real = 0\n",
    "    for inputs_real, _ in test_loader_real:\n",
    "        labels_real = torch.ones(inputs_real.size(0), 1).to(device)\n",
    "        outputs_real = model(inputs_real.to(device))\n",
    "        predictions_real = (outputs_real > 0.5).float()\n",
    "        correct_real += (predictions_real == labels_real).sum().item()\n",
    "        total_real += labels_real.size(0)\n",
    "\n",
    "    accuracy_fake = correct_fake / total_fake if total_fake > 0 else 0\n",
    "    accuracy_real = correct_real / total_real if total_real > 0 else 0\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss Fake: {loss_fake.item()}, Loss Real: {loss_real.item()}')\n",
    "    print(f'Accuracy Fake: {accuracy_fake}, Accuracy Real: {accuracy_real}')\n",
    "\n",
    "    # Vuelve a poner el modelo en modo de entrenamiento\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_dataset_fake = datasets.ImageFolder(root='test_fake', transform=data_transform)\n",
    "test_dataset_real = datasets.ImageFolder(root='test_real', transform=data_transform)\n",
    "\n",
    "test_loader_fake = DataLoader(test_dataset_fake, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader_real = DataLoader(test_dataset_real, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "correct_fake, total_fake = 0, 0\n",
    "correct_real, total_real = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs_fake, _ in test_loader_fake:\n",
    "        labels_fake = torch.zeros(inputs_fake.size(0), 1)\n",
    "        outputs_fake = model(inputs_fake)\n",
    "        predictions_fake = (outputs_fake > 0.5).float()\n",
    "        total_fake += labels_fake.size(0)\n",
    "        correct_fake += (predictions_fake == labels_fake).sum().item()\n",
    "\n",
    "    for inputs_real, _ in test_loader_real:\n",
    "        labels_real = torch.ones(inputs_real.size(0), 1)\n",
    "        outputs_real = model(inputs_real)\n",
    "        predictions_real = (outputs_real > 0.5).float()\n",
    "        total_real += labels_real.size(0)\n",
    "        correct_real += (predictions_real == labels_real).sum().item()\n",
    "\n",
    "accuracy_fake = correct_fake / total_fake\n",
    "accuracy_real = correct_real / total_real\n",
    "\n",
    "print(f'Accuracy on fake images: {accuracy_fake * 100:.2f}%')\n",
    "print(f'Accuracy on real images: {accuracy_real * 100:.2f}%')\n",
    "\n",
    "# Visualizar algunas predicciones\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Desnormalizar\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "'''\n",
    "# Mostrar algunas imágenes de prueba\n",
    "dataiter_fake = iter(test_loader_fake)\n",
    "images_fake, _ = dataiter_fake.next()\n",
    "\n",
    "dataiter_real = iter(test_loader_real)\n",
    "images_real, _ = dataiter_real.next()\n",
    "\n",
    "# Imágenes de caras generadas\n",
    "imshow(torchvision.utils.make_grid(images_fake))\n",
    "outputs_fake = model(images_fake)\n",
    "predictions_fake = (outputs_fake > 0.5).float()\n",
    "print(f'Predictions for fake images: {predictions_fake.view(-1)}')\n",
    "\n",
    "# Imágenes de caras reales\n",
    "imshow(torchvision.utils.make_grid(images_real))\n",
    "outputs_real = model(images_real)\n",
    "predictions_real = (outputs_real > 0.5).float()\n",
    "print(f'Predictions for real images: {predictions_real.view(-1)}')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
