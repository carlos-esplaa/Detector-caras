{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./Datos/real_and_fake_face\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos después de la normalización:\n"
     ]
    }
   ],
   "source": [
    "def normalize_fake_images(original_directory, normalized_directory):\n",
    "    # Crear el directorio normalizado si no existe\n",
    "    os.makedirs(normalized_directory, exist_ok=True)\n",
    "\n",
    "    category = \"training_fake\"\n",
    "    category_path = os.path.join(original_directory, category)\n",
    "\n",
    "    if os.path.isdir(category_path):\n",
    "        normalized_category_path = os.path.join(normalized_directory, category)\n",
    "        os.makedirs(normalized_category_path, exist_ok=True)\n",
    "\n",
    "        for filename in os.listdir(category_path):\n",
    "            if filename.endswith((\".jpg\", \".png\")):\n",
    "                img_path = os.path.join(category_path, filename)\n",
    "\n",
    "                # Extraer información del nombre del archivo\n",
    "                parts = filename.split('_')\n",
    "                difficulty_part = parts[1] if len(parts) > 1 else None\n",
    "                number_part = parts[2] if len(parts) > 2 else None\n",
    "\n",
    "                # Construir el nuevo nombre basado en la información extraída\n",
    "                new_filename = f\"fake_{difficulty_part}_{number_part}\" if difficulty_part else f\"fake_{number_part}\"\n",
    "                new_path = os.path.join(normalized_category_path, new_filename)\n",
    "\n",
    "                # Verificar si el archivo con el nuevo nombre ya existe, y cambiar el nombre si es necesario\n",
    "                count = 1\n",
    "                while os.path.exists(new_path):\n",
    "                    new_filename = f\"fake_{difficulty_part}_{number_part}_{count}\" if difficulty_part else f\"fake_{number_part}_{count}\"\n",
    "                    new_path = os.path.join(normalized_category_path, new_filename)\n",
    "                    count += 1\n",
    "\n",
    "                try:\n",
    "                    # Renombrar el archivo\n",
    "                    os.rename(img_path, new_path)\n",
    "                    print(\"Renamed:\", filename, \"to\", new_filename)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error renaming {filename}: {e}\")\n",
    "\n",
    "# Directorios originales\n",
    "image_directory_fake = \"./Datos/real_and_fake_face/training_fake\"\n",
    "\n",
    "# Directorios normalizados\n",
    "normalized_image_directory = \"./Datos/normalized_real_and_fake_face\"\n",
    "\n",
    "# Normalizar solo los archivos de la carpeta training_fake\n",
    "normalize_fake_images(image_directory_fake, normalized_image_directory)\n",
    "\n",
    "# Verificar si los nombres de los archivos se han cambiado correctamente\n",
    "print(\"Archivos después de la normalización:\")\n",
    "for filename in os.listdir(normalized_image_directory):\n",
    "    print(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aumento de datos y transformaciones\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Cargar datos\n",
    "train_dataset = datasets.ImageFolder(directory, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(directory, transform=val_transform)\n",
    "\n",
    "# Cargador de datos\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del modelo y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fenix\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fenix\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]\n",
      "Fold 1/5, Train Loss: 0.6933, Train Accuracy: 52.82%\n",
      "Fold 1/5, Validation Accuracy: 52.32%\n",
      "Fold 2/5, Train Loss: 0.6694, Train Accuracy: 54.26%\n",
      "Fold 2/5, Validation Accuracy: 61.76%\n",
      "Fold 3/5, Train Loss: 0.6526, Train Accuracy: 58.54%\n",
      "Fold 3/5, Validation Accuracy: 59.80%\n",
      "Fold 4/5, Train Loss: 0.6340, Train Accuracy: 60.13%\n",
      "Fold 4/5, Validation Accuracy: 63.48%\n",
      "Fold 5/5, Train Loss: 0.6105, Train Accuracy: 64.85%\n",
      "Fold 5/5, Validation Accuracy: 58.09%\n",
      "Epoch [2/5]\n",
      "Fold 1/5, Train Loss: 0.5812, Train Accuracy: 65.38%\n",
      "Fold 1/5, Validation Accuracy: 68.46%\n",
      "Fold 2/5, Train Loss: 0.5642, Train Accuracy: 67.91%\n",
      "Fold 2/5, Validation Accuracy: 72.06%\n",
      "Fold 3/5, Train Loss: 0.5465, Train Accuracy: 69.14%\n",
      "Fold 3/5, Validation Accuracy: 70.34%\n",
      "Fold 4/5, Train Loss: 0.5277, Train Accuracy: 71.34%\n",
      "Fold 4/5, Validation Accuracy: 67.89%\n",
      "Fold 5/5, Train Loss: 0.5047, Train Accuracy: 73.24%\n",
      "Fold 5/5, Validation Accuracy: 76.72%\n",
      "Epoch [3/5]\n",
      "Fold 1/5, Train Loss: 0.4763, Train Accuracy: 75.18%\n",
      "Fold 1/5, Validation Accuracy: 74.57%\n",
      "Fold 2/5, Train Loss: 0.4891, Train Accuracy: 73.97%\n",
      "Fold 2/5, Validation Accuracy: 76.96%\n",
      "Fold 3/5, Train Loss: 0.4473, Train Accuracy: 77.71%\n",
      "Fold 3/5, Validation Accuracy: 78.43%\n",
      "Fold 4/5, Train Loss: 0.4435, Train Accuracy: 78.14%\n",
      "Fold 4/5, Validation Accuracy: 79.66%\n",
      "Fold 5/5, Train Loss: 0.4459, Train Accuracy: 77.40%\n",
      "Fold 5/5, Validation Accuracy: 79.17%\n",
      "Epoch [4/5]\n",
      "Fold 1/5, Train Loss: 0.4086, Train Accuracy: 79.17%\n",
      "Fold 1/5, Validation Accuracy: 81.91%\n",
      "Fold 2/5, Train Loss: 0.3979, Train Accuracy: 79.91%\n",
      "Fold 2/5, Validation Accuracy: 77.21%\n",
      "Fold 3/5, Train Loss: 0.3696, Train Accuracy: 82.06%\n",
      "Fold 3/5, Validation Accuracy: 80.64%\n",
      "Fold 4/5, Train Loss: 0.3834, Train Accuracy: 80.59%\n",
      "Fold 4/5, Validation Accuracy: 80.15%\n",
      "Fold 5/5, Train Loss: 0.3678, Train Accuracy: 82.55%\n",
      "Fold 5/5, Validation Accuracy: 83.09%\n",
      "Epoch [5/5]\n",
      "Fold 1/5, Train Loss: 0.3490, Train Accuracy: 81.92%\n",
      "Fold 1/5, Validation Accuracy: 84.11%\n",
      "Fold 2/5, Train Loss: 0.3440, Train Accuracy: 83.34%\n",
      "Fold 2/5, Validation Accuracy: 84.07%\n",
      "Fold 3/5, Train Loss: 0.3339, Train Accuracy: 83.71%\n",
      "Fold 3/5, Validation Accuracy: 82.11%\n",
      "Fold 4/5, Train Loss: 0.3599, Train Accuracy: 83.34%\n",
      "Fold 4/5, Validation Accuracy: 85.05%\n",
      "Fold 5/5, Train Loss: 0.3083, Train Accuracy: 85.55%\n",
      "Fold 5/5, Validation Accuracy: 84.07%\n",
      "Fin del entrenamiento\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo\n",
    "resnet18_model = models.resnet18(pretrained=True)\n",
    "resnet18_model.fc = nn.Sequential(\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ELU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, 1)\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18_model = resnet18_model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(resnet18_model.parameters(), lr=0.0001)\n",
    "\n",
    "# Número de divisiones para la validación cruzada\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Número de épocas\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "\n",
    "    # Validación cruzada\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "        train_fold = torch.utils.data.Subset(train_dataset, train_idx)\n",
    "        val_fold = torch.utils.data.Subset(train_dataset, val_idx)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_fold, batch_size=128, shuffle=True, num_workers=4)\n",
    "        val_loader = torch.utils.data.DataLoader(val_fold, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "        resnet18_model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet18_model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            correct_predictions += (predictions == labels.unsqueeze(1)).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        average_loss = running_loss / len(train_loader)\n",
    "        accuracy = correct_predictions / total_samples\n",
    "        print(f'Fold {fold + 1}/{n_splits}, Train Loss: {average_loss:.4f}, Train Accuracy: {accuracy:.2%}')\n",
    "\n",
    "        resnet18_model.eval()\n",
    "        correct_predictions_val = 0\n",
    "        total_samples_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs_val, labels_val in val_loader:\n",
    "                inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
    "\n",
    "                outputs_val = resnet18_model(inputs_val)\n",
    "                predictions_val = (outputs_val > 0.5).float()\n",
    "\n",
    "                correct_predictions_val += (predictions_val == labels_val.unsqueeze(1)).sum().item()\n",
    "                total_samples_val += labels_val.size(0)\n",
    "\n",
    "        accuracy_val = correct_predictions_val / total_samples_val\n",
    "        print(f'Fold {fold + 1}/{n_splits}, Validation Accuracy: {accuracy_val:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - After all epochs, Accuracy: 83.33%\n",
      "Total de muestras evaluadas: 408\n",
      "Total de predicciones correctas: 107\n",
      "Total de predicciones incorrectas: 21\n"
     ]
    }
   ],
   "source": [
    "def get_label(value, threshold=0.5):\n",
    "    return 'real' if value > threshold else 'fake'\n",
    "\n",
    "# Validación del modelo después de todas las épocas\n",
    "resnet18_model.eval()\n",
    "correct_predictions_val = 0\n",
    "total_samples_val = 0\n",
    "predicted_labels_val = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs_val, labels_val in val_loader:\n",
    "        inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
    "\n",
    "        outputs_val = resnet18_model(inputs_val)\n",
    "        predictions_val = (outputs_val > 0.5).float()\n",
    "\n",
    "        correct_predictions_val += (predictions_val == labels_val.unsqueeze(1)).sum().item()\n",
    "        total_samples_val += labels_val.size(0)\n",
    "\n",
    "        predicted_labels_val.extend(predictions_val.cpu().numpy().tolist())  # Guardar las predicciones\n",
    "\n",
    "# Calcular métricas al final de todas las épocas en el conjunto de validación\n",
    "accuracy_val = correct_predictions_val / total_samples_val\n",
    "print(f'Validation - After all epochs, Accuracy: {accuracy_val:.2%}')\n",
    "\n",
    "# Obtener un lote de imágenes y etiquetas del conjunto de validación\n",
    "validation_images, validation_labels = next(iter(val_loader))\n",
    "\n",
    "# Mover el modelo a la GPU si está disponible\n",
    "resnet18_model = resnet18_model.to(device)\n",
    "\n",
    "# Obtener predicciones del modelo\n",
    "with torch.no_grad():\n",
    "    resnet18_model.eval()\n",
    "    outputs = resnet18_model(validation_images.to(device))\n",
    "    predictions = torch.sigmoid(outputs)\n",
    "\n",
    "# Umbral para clasificación binaria\n",
    "threshold = 0.5\n",
    "\n",
    "# Contadores para aciertos e incorrectos\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# Validación sin mostrar imágenes y nombres\n",
    "for i in range(len(validation_images)):\n",
    "    predicted_label = get_label(predictions[i].item(), threshold)\n",
    "    actual_label = get_label(validation_labels[i].item(), threshold)\n",
    "\n",
    "    # Imprimir si la predicción fue correcta e incorrecta\n",
    "    if predicted_label == actual_label:\n",
    "        correct_count += 1\n",
    "    else:\n",
    "        incorrect_count += 1\n",
    "\n",
    "# Imprimir el número total de muestras y resultados\n",
    "print(f\"Total de muestras evaluadas: {total_samples_val}\")\n",
    "print(f\"Total de predicciones correctas: {correct_count}\")\n",
    "print(f\"Total de predicciones incorrectas: {incorrect_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
