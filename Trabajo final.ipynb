{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de los datos\n",
    "directory = \"./Datos/real_and_fake_face\"\n",
    "\n",
    "# Preprocesar imágenes\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith((\".jpg\", \".png\")):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert('RGB')\n",
    "            img = img.resize((256, 256))\n",
    "            img.save(img_path)\n",
    "            print(\"Converted: \", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aumento de datos y transformaciones\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Cargar datos\n",
    "train_dataset = datasets.ImageFolder(directory, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(directory, transform=val_transform)\n",
    "\n",
    "# Cargador de datos\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del modelo y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2]\n",
      "Fold 1/5, Train Loss: 0.6872, Train Accuracy: 50.61%\n",
      "Fold 1/5, Validation Accuracy: 51.34%\n",
      "Fold 2/5, Train Loss: 0.6626, Train Accuracy: 56.64%\n",
      "Fold 2/5, Validation Accuracy: 61.52%\n",
      "Fold 3/5, Train Loss: 0.6255, Train Accuracy: 61.48%\n",
      "Fold 3/5, Validation Accuracy: 58.58%\n",
      "Fold 4/5, Train Loss: 0.6179, Train Accuracy: 62.65%\n",
      "Fold 4/5, Validation Accuracy: 66.42%\n",
      "Fold 5/5, Train Loss: 0.5890, Train Accuracy: 65.71%\n",
      "Fold 5/5, Validation Accuracy: 61.27%\n",
      "Epoch [2/2]\n",
      "Fold 1/5, Train Loss: 0.5671, Train Accuracy: 68.32%\n",
      "Fold 1/5, Validation Accuracy: 69.19%\n",
      "Fold 2/5, Train Loss: 0.5543, Train Accuracy: 69.44%\n",
      "Fold 2/5, Validation Accuracy: 63.97%\n",
      "Fold 3/5, Train Loss: 0.5410, Train Accuracy: 70.36%\n",
      "Fold 3/5, Validation Accuracy: 72.30%\n",
      "Fold 4/5, Train Loss: 0.5063, Train Accuracy: 72.63%\n",
      "Fold 4/5, Validation Accuracy: 75.49%\n",
      "Fold 5/5, Train Loss: 0.4807, Train Accuracy: 76.42%\n",
      "Fold 5/5, Validation Accuracy: 77.45%\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo\n",
    "resnet18_model = models.resnet18(pretrained=True)\n",
    "resnet18_model.fc = nn.Sequential(\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ELU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, 1)\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18_model = resnet18_model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(resnet18_model.parameters(), lr=0.0001)\n",
    "\n",
    "# Número de divisiones para la validación cruzada\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Número de épocas\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "\n",
    "    # Validación cruzada\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "        train_fold = torch.utils.data.Subset(train_dataset, train_idx)\n",
    "        val_fold = torch.utils.data.Subset(train_dataset, val_idx)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_fold, batch_size=128, shuffle=True, num_workers=4)\n",
    "        val_loader = torch.utils.data.DataLoader(val_fold, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "        resnet18_model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet18_model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            correct_predictions += (predictions == labels.unsqueeze(1)).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        average_loss = running_loss / len(train_loader)\n",
    "        accuracy = correct_predictions / total_samples\n",
    "        print(f'Fold {fold + 1}/{n_splits}, Train Loss: {average_loss:.4f}, Train Accuracy: {accuracy:.2%}')\n",
    "\n",
    "        resnet18_model.eval()\n",
    "        correct_predictions_val = 0\n",
    "        total_samples_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs_val, labels_val in val_loader:\n",
    "                inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
    "\n",
    "                outputs_val = resnet18_model(inputs_val)\n",
    "                predictions_val = (outputs_val > 0.5).float()\n",
    "\n",
    "                correct_predictions_val += (predictions_val == labels_val.unsqueeze(1)).sum().item()\n",
    "                total_samples_val += labels_val.size(0)\n",
    "\n",
    "        accuracy_val = correct_predictions_val / total_samples_val\n",
    "        print(f'Fold {fold + 1}/{n_splits}, Validation Accuracy: {accuracy_val:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - After all epochs, Accuracy: 76.96%\n",
      "Sample 1: Predicted: fake, Actual: real\n",
      "Sample 2: Predicted: fake, Actual: fake\n",
      "Sample 3: Predicted: real, Actual: fake\n",
      "Sample 4: Predicted: fake, Actual: real\n",
      "Sample 5: Predicted: real, Actual: fake\n",
      "Sample 6: Predicted: fake, Actual: real\n",
      "Sample 7: Predicted: fake, Actual: fake\n",
      "Sample 8: Predicted: fake, Actual: fake\n",
      "Sample 9: Predicted: fake, Actual: fake\n",
      "Sample 10: Predicted: real, Actual: fake\n",
      "Sample 11: Predicted: real, Actual: fake\n",
      "Sample 12: Predicted: fake, Actual: real\n",
      "Sample 13: Predicted: fake, Actual: fake\n",
      "Sample 14: Predicted: fake, Actual: fake\n",
      "Sample 15: Predicted: real, Actual: real\n",
      "Sample 16: Predicted: real, Actual: real\n",
      "Sample 17: Predicted: fake, Actual: fake\n",
      "Sample 18: Predicted: real, Actual: real\n",
      "Sample 19: Predicted: real, Actual: real\n",
      "Sample 20: Predicted: fake, Actual: real\n",
      "Sample 21: Predicted: real, Actual: real\n",
      "Sample 22: Predicted: fake, Actual: real\n",
      "Sample 23: Predicted: real, Actual: real\n",
      "Sample 24: Predicted: fake, Actual: fake\n",
      "Sample 25: Predicted: fake, Actual: fake\n",
      "Sample 26: Predicted: fake, Actual: fake\n",
      "Sample 27: Predicted: fake, Actual: fake\n",
      "Sample 28: Predicted: real, Actual: fake\n",
      "Sample 29: Predicted: real, Actual: real\n",
      "Sample 30: Predicted: fake, Actual: real\n",
      "Sample 31: Predicted: real, Actual: fake\n",
      "Sample 32: Predicted: fake, Actual: real\n",
      "Sample 33: Predicted: real, Actual: real\n",
      "Sample 34: Predicted: real, Actual: real\n",
      "Sample 35: Predicted: fake, Actual: fake\n",
      "Sample 36: Predicted: fake, Actual: fake\n",
      "Sample 37: Predicted: fake, Actual: fake\n",
      "Sample 38: Predicted: fake, Actual: fake\n",
      "Sample 39: Predicted: real, Actual: real\n",
      "Sample 40: Predicted: fake, Actual: fake\n",
      "Sample 41: Predicted: fake, Actual: fake\n",
      "Sample 42: Predicted: real, Actual: real\n",
      "Sample 43: Predicted: real, Actual: fake\n",
      "Sample 44: Predicted: real, Actual: real\n",
      "Sample 45: Predicted: fake, Actual: real\n",
      "Sample 46: Predicted: real, Actual: real\n",
      "Sample 47: Predicted: fake, Actual: fake\n",
      "Sample 48: Predicted: fake, Actual: real\n",
      "Sample 49: Predicted: real, Actual: real\n",
      "Sample 50: Predicted: fake, Actual: fake\n",
      "Sample 51: Predicted: real, Actual: fake\n",
      "Sample 52: Predicted: real, Actual: real\n",
      "Sample 53: Predicted: fake, Actual: fake\n",
      "Sample 54: Predicted: real, Actual: real\n",
      "Sample 55: Predicted: fake, Actual: fake\n",
      "Sample 56: Predicted: real, Actual: real\n",
      "Sample 57: Predicted: real, Actual: real\n",
      "Sample 58: Predicted: real, Actual: real\n",
      "Sample 59: Predicted: real, Actual: real\n",
      "Sample 60: Predicted: real, Actual: real\n",
      "Sample 61: Predicted: fake, Actual: fake\n",
      "Sample 62: Predicted: real, Actual: real\n",
      "Sample 63: Predicted: real, Actual: real\n",
      "Sample 64: Predicted: fake, Actual: fake\n",
      "Sample 65: Predicted: real, Actual: real\n",
      "Sample 66: Predicted: fake, Actual: real\n",
      "Sample 67: Predicted: fake, Actual: fake\n",
      "Sample 68: Predicted: real, Actual: real\n",
      "Sample 69: Predicted: real, Actual: real\n",
      "Sample 70: Predicted: real, Actual: real\n",
      "Sample 71: Predicted: fake, Actual: fake\n",
      "Sample 72: Predicted: fake, Actual: real\n",
      "Sample 73: Predicted: real, Actual: real\n",
      "Sample 74: Predicted: fake, Actual: real\n",
      "Sample 75: Predicted: fake, Actual: fake\n",
      "Sample 76: Predicted: fake, Actual: fake\n",
      "Sample 77: Predicted: fake, Actual: fake\n",
      "Sample 78: Predicted: real, Actual: real\n",
      "Sample 79: Predicted: real, Actual: real\n",
      "Sample 80: Predicted: real, Actual: real\n",
      "Sample 81: Predicted: fake, Actual: fake\n",
      "Sample 82: Predicted: real, Actual: fake\n",
      "Sample 83: Predicted: fake, Actual: fake\n",
      "Sample 84: Predicted: fake, Actual: real\n",
      "Sample 85: Predicted: real, Actual: real\n",
      "Sample 86: Predicted: fake, Actual: fake\n",
      "Sample 87: Predicted: fake, Actual: fake\n",
      "Sample 88: Predicted: fake, Actual: fake\n",
      "Sample 89: Predicted: fake, Actual: real\n",
      "Sample 90: Predicted: real, Actual: real\n",
      "Sample 91: Predicted: fake, Actual: fake\n",
      "Sample 92: Predicted: fake, Actual: real\n",
      "Sample 93: Predicted: real, Actual: real\n",
      "Sample 94: Predicted: real, Actual: real\n",
      "Sample 95: Predicted: real, Actual: real\n",
      "Sample 96: Predicted: fake, Actual: fake\n",
      "Sample 97: Predicted: fake, Actual: real\n",
      "Sample 98: Predicted: fake, Actual: fake\n",
      "Sample 99: Predicted: real, Actual: real\n",
      "Sample 100: Predicted: fake, Actual: real\n",
      "\n",
      "Total de muestras evaluadas: 100\n",
      "Total de predicciones correctas: 73\n",
      "Total de predicciones incorrectas: 27\n"
     ]
    }
   ],
   "source": [
    "# Función para convertir las predicciones y etiquetas a \"real\" o \"fake\"\n",
    "def get_label(value, threshold=0.5):\n",
    "    return 'real' if value > threshold else 'fake'\n",
    "\n",
    "# Validación del modelo después de todas las épocas\n",
    "resnet18_model.eval()\n",
    "correct_predictions_val = 0\n",
    "total_samples_val = 0\n",
    "predicted_labels_val = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs_val, labels_val in val_loader:\n",
    "        inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
    "\n",
    "        outputs_val = resnet18_model(inputs_val)\n",
    "        predictions_val = (outputs_val > 0.5).float()\n",
    "\n",
    "        correct_predictions_val += (predictions_val == labels_val.unsqueeze(1)).sum().item()\n",
    "        total_samples_val += labels_val.size(0)\n",
    "\n",
    "        predicted_labels_val.extend(predictions_val.cpu().numpy().tolist())  # Guardar las predicciones\n",
    "\n",
    "# Calcular métricas al final de todas las épocas en el conjunto de validación\n",
    "accuracy_val = correct_predictions_val / total_samples_val\n",
    "print(f'Validation - After all epochs, Accuracy: {accuracy_val:.2%}')\n",
    "\n",
    "# Obtener un lote de imágenes y etiquetas del conjunto de validación\n",
    "validation_images, validation_labels = next(iter(val_loader))\n",
    "\n",
    "# Mover el modelo a la GPU si está disponible\n",
    "resnet18_model = resnet18_model.to(device)\n",
    "\n",
    "# Obtener predicciones del modelo\n",
    "with torch.no_grad():\n",
    "    resnet18_model.eval()\n",
    "    outputs = resnet18_model(validation_images.to(device))\n",
    "    predictions = torch.sigmoid(outputs)\n",
    "\n",
    "# Umbral para clasificación binaria\n",
    "threshold = 0.5\n",
    "\n",
    "# Contadores para aciertos e incorrectos\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# Validación sin mostrar imágenes y nombres\n",
    "sample_limit = 100\n",
    "for i in range(min(sample_limit, len(validation_images))):\n",
    "    predicted_label = get_label(predictions[i].item(), threshold)\n",
    "    actual_label = get_label(validation_labels[i].item(), threshold)\n",
    "\n",
    "    # Imprimir si la predicción fue correcta e incorrecta\n",
    "    if predicted_label == actual_label:\n",
    "        correct_count += 1\n",
    "    else:\n",
    "        incorrect_count += 1\n",
    "\n",
    "    # Imprimir información sobre la muestra actual\n",
    "    print(f\"Sample {i + 1}: Predicted: {predicted_label}, Actual: {actual_label}\")\n",
    "\n",
    "# Imprimir el número total de muestras y resultados\n",
    "print(f\"\\nTotal de muestras evaluadas: {min(sample_limit, len(validation_images))}\")\n",
    "print(f\"Total de predicciones correctas: {correct_count}\")\n",
    "print(f\"Total de predicciones incorrectas: {incorrect_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
